{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "char-Baseline_batch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeLCkRK-eYKA",
        "outputId": "4fdbb86c-6636-4e45-f43d-a70e3341c065"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "import torchtext\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ppp6QeOed3y"
      },
      "source": [
        "\n",
        "p_intent = []\n",
        "p_snippet = []\n",
        "c = 0\n",
        "iit = []\n",
        "with open('x.txt', 'r',encoding='UTF-8') as intent:\n",
        "    for i in intent:\n",
        "      if i[:-1].lower() not in p_intent:\n",
        "        iit.append(c)\n",
        "      c+=1\n",
        "      p_intent.append(i[:-1].lower())\n",
        "p_intentn = []\n",
        "with open('x.txt', 'r',encoding='UTF-8') as intent:\n",
        "    for i in intent:\n",
        "      p_intentn.append(i[:-1].lower())\n",
        "with open('y.txt', 'r',encoding='UTF-8') as snippet:\n",
        "    for i in snippet:\n",
        "      i = i[:-1]\n",
        "      if i[-1]==' ':\n",
        "        i=i[:-1]\n",
        "      p_snippet.append(i.lower())\n",
        "  \n",
        "train_pairs = [[p_intentn[i],p_snippet[i]] for i in iit]\n",
        "p_intentval = []\n",
        "p_snippetval = []\n",
        "iiv = []\n",
        "c= 0\n",
        "with open('xv.txt', 'r',encoding='UTF-8') as intent:\n",
        "    for i in intent:\n",
        "      if i[:-1].lower() not in p_intent and i[:-1].lower() not in p_intentval:\n",
        "        iiv.append(c)\n",
        "      \n",
        "      p_intentval.append(i[:-1].lower())\n",
        "      c+=1\n",
        "p_intentvaln = []\n",
        "with open('xv.txt', 'r',encoding='UTF-8') as intent:\n",
        "    for i in intent:\n",
        "      p_intentvaln.append(i[:-1].lower())\n",
        "      c+=1\n",
        "with open('yv.txt', 'r',encoding='UTF-8') as snippet:\n",
        "    for i in snippet:\n",
        "      #i = i.split(' ')\n",
        "      i = i[:-1]\n",
        "      if i[-1]==' ':\n",
        "        i=i[:-1]\n",
        "      # if i.lower() not in p_snippet:\n",
        "      p_snippetval.append(i.lower())\n",
        "val_pairs = [[p_intentvaln[i],p_snippetval[i]] for i in iiv]\n",
        "p_intenttest = []\n",
        "p_snippettest = []\n",
        "ii = []\n",
        "c= 0\n",
        "with open('xt.txt', 'r',encoding='UTF-8') as intent:\n",
        "    for i in intent:\n",
        "      if i[:-1].lower() not in p_intent and i[:-1].lower() not in p_intenttest:\n",
        "        ii.append(c)\n",
        "      c+=1\n",
        "      p_intenttest.append(i[:-1].lower())\n",
        "with open('yt.txt', 'r',encoding='UTF-8') as snippet:\n",
        "    for i in snippet:\n",
        "      i = i[:-1]\n",
        "      if i[-1]==' ':\n",
        "        i=i[:-1]\n",
        "      # if i.lower() not in p_snippet:\n",
        "      p_snippettest.append(i.lower())\n",
        "test_pairs = [[p_intenttest[i],p_snippettest[i]] for i in ii]\n",
        "p_intenttest1 = []\n",
        "p_snippettest1 = []\n",
        "with open('xt1.txt', 'r',encoding='UTF-8') as intent:\n",
        "    for i in intent:\n",
        "      \n",
        "      p_intenttest1.append(i[:-1].lower())\n",
        "with open('yt1.txt', 'r',encoding='UTF-8') as snippet:\n",
        "    for i in snippet:\n",
        "      i = i[:-1]\n",
        "      if i[-1]==' ':\n",
        "        i=i[:-1]\n",
        "      p_snippettest1.append(i.lower())\n",
        "test_pairs1 = [[p_intenttest1[i],p_snippettest1[i]] for i in ii]\n",
        "p_intenttest2 = []\n",
        "p_snippettest2 = []\n",
        "with open('xt2.txt', 'r',encoding='UTF-8') as intent:\n",
        "    for i in intent:\n",
        "      \n",
        "      p_intenttest2.append(i[:-1].lower())\n",
        "with open('yt2.txt', 'r',encoding='UTF-8') as snippet:\n",
        "    for i in snippet:\n",
        "      i = i[:-1]\n",
        "      if i[-1]==' ':\n",
        "        i=i[:-1]\n",
        "      p_snippettest2.append(i.lower())\n",
        "test_pairs2 = [[p_intenttest2[i],p_snippettest2[i]] for i in ii]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrphaZPmUrqJ"
      },
      "source": [
        "\n",
        "# p_intentextra = []\n",
        "# p_snippetextra = []\n",
        "# c = 0\n",
        "# iite = []\n",
        "# with open('xextra.txt', 'r',encoding='UTF-8') as intent:\n",
        "#     for i in intent:\n",
        "#       if i[:-1].lower() not in p_intentextra and i[:-1].lower() not in p_intent and i[:-1].lower() not in p_intenttest and i[:-1].lower() not in p_intentval:\n",
        "#         iite.append(c)\n",
        "#       c+=1\n",
        "#       p_intentextra.append(i[:-1].lower())\n",
        "\n",
        "# with open('yextra.txt', 'r',encoding='UTF-8') as snippet:\n",
        "#     for i in snippet:\n",
        "#       p_snippetextra.append(i[:-1].lower())\n",
        "# extratrain = [[p_intentextra[i],p_snippetextra[i]] for i in iite]\n",
        "# train_pairs = train_pairs+extratrain"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zbGKi6aOz2k"
      },
      "source": [
        "## Char-level pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djTMG8o2g8pH"
      },
      "source": [
        "\n",
        "SRC_TEXT = torchtext.legacy.data.Field(sequential=True,\n",
        "                                # lower=True,\n",
        "                                # fix_length=MAX_LENGTH + 2,\n",
        "                                # preprocessing=lambda x: ['sos'] + x + ['eos'],\n",
        "                                # after tokenizing but before numericalizing\n",
        "                                # postprocessing # after numericalizing but before the numbers are turned into a Tensor\n",
        "                                )\n",
        "TARG_TEXT = torchtext.legacy.data.Field(sequential=True,\n",
        "                                #  tokenize=tokenizer,\n",
        "                                 # lower=True,\n",
        "                                #  fix_length=MAX_LENGTH + 2,\n",
        "                                #  preprocessing=lambda x: ['sos'] + x + ['eos'],\n",
        "                                 )\n",
        "                                 \n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtAs83F9RjC5"
      },
      "source": [
        "ptrainx = [['sos']+list(x[0])+['eos'] for x in train_pairs]\n",
        "ptrainy = [['sos']+list(x[1])+['eos'] for x in train_pairs]\n",
        "pvalx = [['sos']+list(x[0])+['eos'] for x in val_pairs]\n",
        "pvaly = [['sos']+list(x[1])+['eos'] for x in val_pairs]\n",
        "ptestx = [['sos']+list(x[0])+['eos'] for x in test_pairs]\n",
        "ptesty = [['sos']+list(x[1])+['eos'] for x in test_pairs]\n",
        "ptestx1 = [['sos']+list(x[0])+['eos'] for x in test_pairs1]\n",
        "ptesty1 = [['sos']+list(x[1])+['eos'] for x in test_pairs1]\n",
        "ptestx2 = [['sos']+list(x[0])+['eos'] for x in test_pairs2]\n",
        "ptesty2 = [['sos']+list(x[1])+['eos'] for x in test_pairs2]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT2bkq24jKHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "899e09c2-20d8-47cc-c900-ebdf5782560d"
      },
      "source": [
        "SRC_TEXT.build_vocab(ptrainx) \n",
        "print(len(SRC_TEXT.vocab))\n",
        "print(SRC_TEXT.vocab.itos[0])\n",
        "print(SRC_TEXT.vocab.itos[1])\n",
        "print(SRC_TEXT.vocab.itos[2])\n",
        "print(SRC_TEXT.vocab.itos[3])\n",
        "print(SRC_TEXT.vocab.stoi['sos'])\n",
        "print(SRC_TEXT.vocab.stoi['eos'])\n",
        "\n",
        "TARG_TEXT.build_vocab(ptrainy)\n",
        "print(len(TARG_TEXT.vocab))\n",
        "print(TARG_TEXT.vocab.itos[0])\n",
        "print(TARG_TEXT.vocab.itos[1])\n",
        "print(TARG_TEXT.vocab.itos[2])\n",
        "print(TARG_TEXT.vocab.itos[3])\n",
        "print(TARG_TEXT.vocab.stoi['sos'])\n",
        "print(TARG_TEXT.vocab.stoi['eos'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55\n",
            "<unk>\n",
            "<pad>\n",
            " \n",
            "e\n",
            "14\n",
            "13\n",
            "62\n",
            "<unk>\n",
            "<pad>\n",
            " \n",
            ")\n",
            "15\n",
            "14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ1HVyjzkLVn"
      },
      "source": [
        "final_trainx = [torch.tensor([SRC_TEXT.vocab.stoi[x] for x in i]) for i in ptrainx]\n",
        "final_trainy = [torch.tensor([TARG_TEXT.vocab.stoi[x] for x in i]) for i in ptrainy]\n",
        "final_valx = [torch.tensor([SRC_TEXT.vocab.stoi[x] for x in i]) for i in pvalx]\n",
        "final_valy = [torch.tensor([TARG_TEXT.vocab.stoi[x] for x in i]) for i in pvaly]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqei5F3-nWGC"
      },
      "source": [
        "final_testx = [torch.tensor([SRC_TEXT.vocab.stoi[x] for x in i]) for i in ptestx]\n",
        "final_testy = [torch.tensor([TARG_TEXT.vocab.stoi[x] for x in i]) for i in ptesty]\n",
        "final_testx1 = [torch.tensor([SRC_TEXT.vocab.stoi[x] for x in i]) for i in ptestx1]\n",
        "final_testy1 = [torch.tensor([TARG_TEXT.vocab.stoi[x] for x in i]) for i in ptesty1]\n",
        "final_testx2 = [torch.tensor([SRC_TEXT.vocab.stoi[x] for x in i]) for i in ptestx2]\n",
        "final_testy2 = [torch.tensor([TARG_TEXT.vocab.stoi[x] for x in i]) for i in ptesty2]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-ARtLvvnYhB"
      },
      "source": [
        "data = list(zip(final_trainx,final_trainy))\n",
        "datav = list(zip(final_valx,final_valy))\n",
        "datat = list(zip(final_testx,final_testy))\n",
        "datat1 = list(zip(final_testx1,final_testy1))\n",
        "datat2 = list(zip(final_testx2,final_testy2))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uso8-DPtnsw5"
      },
      "source": [
        "def collate_fn(data):\n",
        "    inputs,targ = zip(*data)\n",
        "    seq_len = torch.tensor([len(i) for i in inputs])\n",
        "    inputs= torch.nn.utils.rnn.pad_sequence(inputs, padding_value=1)\n",
        "    targ = torch.nn.utils.rnn.pad_sequence(targ, padding_value=1)\n",
        "\n",
        "    return inputs,targ,seq_len\n",
        "d = torch.utils.data.DataLoader(datat, batch_size = 64 ,shuffle = False,collate_fn= collate_fn)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpXKzWr8rVYF"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size,embedding_size,hidden_size,num_layers,dropout_rate):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.gru = nn.GRU(embedding_size, hidden_size,num_layers , bidirectional = True, dropout=dropout_rate)\n",
        "        self.fc = nn.Linear(hidden_size*2, hidden_size)\n",
        "        self.r = torch.nn.ReLU()\n",
        "    def forward(self, input,seq_length):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, seq_length,enforce_sorted=False)\n",
        "        output, hidden = self.gru(packed)\n",
        "        output,_ = nn.utils.rnn.pad_packed_sequence(output,batch_first=False,total_length=max(seq_length),)\n",
        "        # print(output.shape)\n",
        "        hidden = torch.cat((hidden[-1],hidden[-2]),dim=1)\n",
        "        hidden = self.r(self.fc(hidden)).unsqueeze(0)\n",
        "        # print(hidden.shape)\n",
        "        return output,hidden\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbj-gxZHYHOs"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size,embedding_size,hidden_size,output_size,num_layers,dropout_rate):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.embedding = nn.Embedding(input_size,embedding_size)\n",
        "        self.gru = nn.GRU(hidden_size*2+embedding_size, hidden_size,num_layers,dropout=dropout_rate)\n",
        "        self.attension = nn.Linear(hidden_size*3,1)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.relu = nn.Tanh()\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "    def forward(self, encoder_output ,input, hidden):\n",
        "        input = input.unsqueeze(0)\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        h_attension = hidden.repeat(encoder_output.size(0),1,1)\n",
        "        attention = self.relu(self.attension(torch.cat((h_attension,encoder_output),dim=2)))\n",
        "        attention = self.softmax(attention)\n",
        "        c = torch.bmm(attention.permute(1,2,0),encoder_output.permute(1,0,2)).permute(1,0,2)\n",
        "        embedded = torch.cat((embedded,c),dim=2)\n",
        "        # print(embedded.shape)\n",
        "        output,hidden = self.gru(embedded,hidden)\n",
        "        pred = self.out(output)\n",
        "        pred = pred.squeeze(0)\n",
        "        return pred,hidden"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFX8AmtXr1j9"
      },
      "source": [
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder,decoder):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "    def forward(self, source,target,s,teacher_force_ratio=0.5,):\n",
        "        batch_size = source.size(1)\n",
        "        target_length = target.size(0)\n",
        "        target_vocab_size = len(TARG_TEXT.vocab)\n",
        "        output_encoder,hidden = self.encoder(source,s)\n",
        "        outputs = torch.zeros(target_length,batch_size,target_vocab_size).to(device)\n",
        "        x = target[0,:]\n",
        "        # print(hidden)\n",
        "        for t in range(1,target_length):\n",
        "          output,hidden = self.decoder(output_encoder,x,hidden)\n",
        "          ### output: batch*vocab_size\n",
        "          outputs[t] = output\n",
        "          pred_max = output.argmax(1)\n",
        "          x = target[t] if random.random() < teacher_force_ratio else pred_max\n",
        "        return outputs"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqzPFug3si71"
      },
      "source": [
        "def train(datat,batch_s,model):\n",
        "  model.train()\n",
        "  d = torch.utils.data.DataLoader(datat, batch_size = batch_s ,shuffle = True,collate_fn= collate_fn)\n",
        "  loss_train = 0\n",
        "  acc_train = 0\n",
        "  for i, (x_train,x_label,s) in enumerate(d,start = 1):\n",
        "      optimizer.zero_grad()\n",
        "      x_train = x_train.to(device)\n",
        "      x_label = x_label.to(device)\n",
        "      predict = model(x_train,x_label,s)\n",
        "      pred_dim = predict.shape[-1]\n",
        "        \n",
        "        # trg = [(trg len - 1) * batch size]\n",
        "        # pred = [(trg len - 1) * batch size, pred_dim]\n",
        "      x_label = x_label[1:].view(-1)\n",
        "      predict = predict[1:].view(-1, pred_dim)\n",
        "      # print(x_label.shape)\n",
        "      loss = criterion(predict, x_label)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      loss_train += loss.item()\n",
        "      _pred = predict.argmax(dim=-1)  # [b, targ_seq_len, target_vocab_size]=>[b, targ_seq_len]\n",
        "      corrects = _pred.eq(x_label) \n",
        "      mask = torch.logical_not(x_label.eq(1)) \n",
        "      corrects *= mask\n",
        "      # print(mask.sum())\n",
        "      # print(corrects.shape)\n",
        "      # print(x_label.shape)\n",
        "      acc_train += corrects.sum().float() / mask.sum()\n",
        "      # corrects *= mask\n",
        "      # print(mask.sum())\n",
        "      # print(corrects.shape)\n",
        "      # print(x_label.shape)\n",
        "      # acc_train += corrects.sum().float() / (x_label.shape[0])\n",
        "  return loss_train/i,acc_train/i\n",
        "\n",
        "def val(datat,batch_s,model):\n",
        "  model.eval()\n",
        "  d = torch.utils.data.DataLoader(datat, batch_size = batch_s ,shuffle = False,collate_fn= collate_fn)\n",
        "  loss_val = 0\n",
        "  acc_val = 0\n",
        "  for i, (x_val,x_label,s) in enumerate(d,start = 1):\n",
        "      with torch.no_grad():\n",
        "        x_val = x_val.to(device)\n",
        "        x_label = x_label.to(device)\n",
        "        predict = model(x_val,x_label,s)\n",
        "    \n",
        "    \n",
        "        \n",
        "        pred_dim = predict.shape[-1]\n",
        "        \n",
        "        # trg = [(trg len - 1) * batch size]\n",
        "        # pred = [(trg len - 1) * batch size, pred_dim]\n",
        "        x_label = x_label[1:].view(-1)\n",
        "        predict = predict[1:].view(-1, pred_dim)\n",
        "      # print(x_label.shape)\n",
        "        loss = criterion(predict, x_label)\n",
        "    \n",
        "        loss_val += loss.item()\n",
        "        _pred = predict.argmax(dim=-1)  # [b, targ_seq_len, target_vocab_size]=>[b, targ_seq_len]\n",
        "        corrects = _pred.eq(x_label) \n",
        "        mask = torch.logical_not(x_label.eq(1)) \n",
        "        corrects *= mask\n",
        "      # print(corrects.shape)\n",
        "      # print(x_label.shape)\n",
        "        acc_val += corrects.sum().float() / mask.sum()\n",
        "        # corrects *= mask\n",
        "      # print(mask.sum())\n",
        "      # print(corrects.shape)\n",
        "      # print(x_label.shape)\n",
        "        # acc_val += corrects.sum().float() / (x_label.shape[0])\n",
        "  return loss_val/i,acc_val/i"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5lleoY2waZE"
      },
      "source": [
        "def predict(sen,trg, model, source_vocab, target_vocab ):\n",
        "\n",
        "    # Convert each source token to integer values using the vocabulary\n",
        "    tokens =  ['sos']+list(sen) + ['eos']\n",
        "    src_indexes = [source_vocab.stoi[token] for token in tokens]\n",
        "    # print(src_indexes)\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\n",
        "    # print(src_tensor.shape)\n",
        "    model.eval()\n",
        "\n",
        "    # Run the forward pass of the encoder\n",
        "    encoder_outputs, hidden = model.encoder(src_tensor,torch.tensor([src_tensor.shape[0]]))\n",
        "\n",
        "    # Take the integer value of <sos> from the target vocabulary.\n",
        "    trg_index = [target_vocab.stoi['sos']]\n",
        "    next_token = torch.LongTensor(trg_index).to(device)\n",
        "\n",
        "    # print(next_token)\n",
        "    trg_indexes = [trg_index[0]]\n",
        "\n",
        "    # outputs = []\n",
        "    with torch.no_grad():\n",
        "        # Use the hidden and cell vector of the Encoder and in loop\n",
        "        # run the forward pass of the OneStepDecoder until some specified\n",
        "        # step (say 50) or when <eos> has been generated by the model.\n",
        "        for i in range(200):\n",
        "            output, hidden = model.decoder(encoder_outputs, next_token, hidden)\n",
        "\n",
        "\n",
        "            # Take the most probable word\n",
        "            \n",
        "            next_token = output.argmax(1)\n",
        "\n",
        "            trg_indexes.append(next_token.item())\n",
        "\n",
        "            predicted = target_vocab.itos[next_token[0]]\n",
        "            # print(predicted)\n",
        "            if predicted == 'eos':\n",
        "                break\n",
        "            # else:\n",
        "            #     outputs.append(predicted)\n",
        "    # if debug:\n",
        "    # print(f'Ground Truth    = {trg}')\n",
        "    # print(f'Predicted Label = {\" \".join(outputs)}')\n",
        "\n",
        "    predicted_words = [target_vocab.itos[i] for i in trg_indexes]\n",
        "\n",
        "    # print(predicted_words[1:-1])\n",
        "\n",
        "    return predicted_words[1:-1]\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KEIuSiYr7iu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6caecafc-a7e8-4c1e-9e96-393832e0e419"
      },
      "source": [
        "### training parameter\n",
        "epoch = 20\n",
        "### model parameter\n",
        "input_size = len(SRC_TEXT.vocab)\n",
        "output_size = len(TARG_TEXT.vocab)\n",
        "encoder_embedding_size = 300\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 600\n",
        "number_layers = 1\n",
        "encoder_dropout_rate = 0.25\n",
        "decoder_dropout_rate = 0.25\n",
        "###\n",
        "\n",
        "enc = Encoder(input_size, encoder_embedding_size, hidden_size, number_layers, encoder_dropout_rate).to(device)\n",
        "dec = Decoder(output_size, decoder_embedding_size, hidden_size,output_size,number_layers, decoder_dropout_rate).to(device)\n",
        "\n",
        "model = Seq2Seq(enc, dec).to(device)\n",
        "criterion = nn.CrossEntropyLoss(ignore_index = 1)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.0005)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "            optimizer , 10,\n",
        "                gamma =0.9)\n",
        "print(enc)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder(\n",
            "  (dropout): Dropout(p=0.25, inplace=False)\n",
            "  (embedding): Embedding(55, 300)\n",
            "  (gru): GRU(300, 600, dropout=0.25, bidirectional=True)\n",
            "  (fc): Linear(in_features=1200, out_features=600, bias=True)\n",
            "  (r): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B_HV9HpVrts"
      },
      "source": [
        "import timeit\n",
        "early_ = []\n",
        "for e in range(100):\n",
        "    # print('epoch: ' + str(e))\n",
        "    start = timeit.default_timer()\n",
        "    t = train(data,100,model)\n",
        "    stop = timeit.default_timer()\n",
        "\n",
        "    print('Time: ', stop - start) \n",
        "    v = val(datav,256,model)\n",
        "    test = val(datat,256,model)\n",
        "    test1 = val(datat1,256,model)\n",
        "    test2 = val(datat2,256,model)\n",
        "    prediction = []\n",
        "    b = [0]\n",
        "    if len(early_)>10:\n",
        "      if v[0]>=early_[e-10]:\n",
        "        print('EPOCH = {} loss: {:.3f}, {}: {:.3f},val_loss: {:.3f}, val_{}: {:.3f},test_loss: {:.3f}, test_{}: {:.3f}, test1_loss: {:.3f},test1_{}: {:.3f},test2_loss: {:.3f},test2_{}: {:.3f}'.format(\n",
        "            e, t[0], \"acc\", t[1], v[0], \"acc\", v[1],test[0], \"acc\", test[1],test1[0], \"acc\", test1[1],test2[0], \"acc\", test2[1]))\n",
        "        break\n",
        "    early_.append(v[0])\n",
        "    scheduler.step()\n",
        "    print('EPOCH = {} loss: {:.3f}, {}: {:.3f},val_loss: {:.3f}, val_{}: {:.3f},test_loss: {:.3f}, test_{}: {:.3f}, test1_loss: {:.3f},test1_{}: {:.3f},test2_loss: {:.3f},test2_{}: {:.3f}'.format(\n",
        "            e, t[0], \"acc\", t[1], v[0], \"acc\", v[1],test[0], \"acc\", test[1],test1[0], \"acc\", test1[1],test2[0], \"acc\", test2[1]))"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4tzciR1NQB2"
      },
      "source": [
        "gt= [[i[1].split()]for i in test_pairs]\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoothie = SmoothingFunction().method4\n",
        "total = 0\n",
        "for i in tqdm(range(len(test_pairs))):\n",
        "       \n",
        "      \n",
        "        references = gt[i]\n",
        "      \n",
        "        candidates = ''.join(predict(test_pairs[i][0],test_pairs[i][1], model, SRC_TEXT.vocab, TARG_TEXT.vocab)).split()\n",
        "\n",
        "        sbs = sentence_bleu(references, candidates,smoothing_function=smoothie)\n",
        "        total+=sbs\n",
        "total*100/len(test_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FXiImLR6UvU"
      },
      "source": [
        "gt= [[i[1].split()]for i in test_pairs1]\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoothie = SmoothingFunction().method4\n",
        "total = 0\n",
        "for i in tqdm(range(len(test_pairs))):\n",
        "       \n",
        "      \n",
        "        references = gt[i]\n",
        "      \n",
        "        candidates = ''.join(predict(test_pairs1[i][0],test_pairs1[i][1], model, SRC_TEXT.vocab, TARG_TEXT.vocab)).split()\n",
        "\n",
        "\n",
        "\n",
        "        total+=sentence_bleu(references, candidates,smoothing_function=smoothie)\n",
        "total*100/len(test_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNnke31ORW1v"
      },
      "source": [
        "gt= [[i[1].split()]for i in test_pairs2]\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "smoothie = SmoothingFunction().method4\n",
        "total = 0\n",
        "for i in tqdm(range(len(test_pairs))):\n",
        "       \n",
        "      \n",
        "        references = gt[i]\n",
        "      \n",
        "        candidates = ''.join(predict(test_pairs2[i][0],test_pairs2[i][1], model, SRC_TEXT.vocab, TARG_TEXT.vocab)).split()\n",
        "\n",
        "\n",
        "\n",
        "        total+=sentence_bleu(references, candidates,smoothing_function=smoothie)\n",
        "total*100/len(test_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKV-FgQjLWgv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}